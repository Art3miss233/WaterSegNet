{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set dataset paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import datetime\n",
    "from lib.dataloader import *\n",
    "\n",
    "uav_set = Path(\"/home/emilia/WaterSegNet/datasets/uav_dataset/\")\n",
    "satelite_set = Path(\"/home/emilia/WaterSegNet/datasets/satelite_dataset/\")\n",
    "full_set = Path(\"/home/emilia/WaterSegNet/datasets/complete_dataset/\")\n",
    "# Directory paths for semantic segmentation dataset\n",
    "root_dir = uav_set\n",
    "\n",
    "dir_test_img = root_dir / \"test/images\"\n",
    "dir_test_mask = root_dir / \"test/labels\"\n",
    "dir_train_img = root_dir / \"train/images\"\n",
    "dir_train_mask = root_dir / \"train/labels\"\n",
    "dir_valid_img = root_dir / \"valid/images\"\n",
    "dir_valid_mask = root_dir / \"valid/labels\"\n",
    "\n",
    "# Directory paths for checkpoints and best models\n",
    "dir_checkpoint = root_dir / \"checkpoints/\"\n",
    "dir_best_model = root_dir / \"best_models/\"\n",
    "dir_best_model /= datetime.datetime.now().strftime(\"%d-%m-%Y-%H-%M\")\n",
    "\n",
    "\n",
    "train_set = SegDataset(dir_train_img, dir_train_mask)\n",
    "valid_set = SegDataset(dir_valid_img, dir_valid_mask)\n",
    "test_set = SegDataset(dir_test_img, dir_test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(6, 15):\n",
    "    sample = test_set[i]\n",
    "    img, mask = sample[\"image\"], sample[\"mask\"]\n",
    "    # for visualization we have to transpose back to HWC\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    # plt.imshow(mask, alpha=0.5, cmap=\"Accent\")\n",
    "    plt.title(\"Padded and resized image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type              | Params\n",
      "-----------------------------------------------------------\n",
      "0 | model                | UnetPlusPlus      | 26.1 M\n",
      "1 | criterion            | BCEWithLogitsLoss | 0     \n",
      "2 | dice_loss            | DiceLoss          | 0     \n",
      "3 | train_metric_tracker | MetricTracker     | 0     \n",
      "4 | val_metric_tracker   | MetricTracker     | 0     \n",
      "5 | test_metric_tracker  | MetricTracker     | 0     \n",
      "-----------------------------------------------------------\n",
      "26.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "26.1 M    Total params\n",
      "52.157    Total estimated model params size (MB)\n",
      "/home/emilia/.local/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:623: UserWarning: Checkpoint directory /home/emilia/WaterSegNet/checkpoints/satelite exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 84/84 [00:21<00:00,  3.96it/s, loss=0.198, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 0.294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 84/84 [00:24<00:00,  3.50it/s, loss=0.212, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.110 >= min_delta = 0.0. New best score: 0.183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 84/84 [00:24<00:00,  3.36it/s, loss=0.226, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 84/84 [00:25<00:00,  3.35it/s, loss=0.0568, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.032 >= min_delta = 0.0. New best score: 0.120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 84/84 [00:24<00:00,  3.40it/s, loss=0.0468, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.059 >= min_delta = 0.0. New best score: 0.060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 84/84 [00:25<00:00,  3.34it/s, loss=0.0363, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.004 >= min_delta = 0.0. New best score: 0.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 84/84 [00:25<00:00,  3.32it/s, loss=0.0271, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.003 >= min_delta = 0.0. New best score: 0.053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 84/84 [00:25<00:00,  3.34it/s, loss=0.0227, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Monitored metric val_loss did not improve in the last 10 records. Best score: 0.053. Signaling Trainer to stop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 84/84 [00:25<00:00,  3.34it/s, loss=0.0227, v_num=0]\n"
     ]
    }
   ],
   "source": [
    "from lib.train import *\n",
    "import segmentation_models_pytorch as smp\n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from segnet.SegNet_model import SegNet\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    "    activation=None,\n",
    ")\n",
    "\n",
    "\n",
    "model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "metrics = torchmetrics.MetricCollection(\n",
    "    torchmetrics.Accuracy(task=\"binary\", num_classes=1, multiclass=False),\n",
    "    torchmetrics.Recall(task=\"binary\", num_classes=1, multiclass=False),\n",
    "    torchmetrics.Precision(task=\"binary\", num_classes=1, multiclass=False),\n",
    "    torchmetrics.F1Score(\n",
    "        task=\"binary\", num_classes=1, multiclass=False\n",
    "    ),  # Dice Coefficient\n",
    ")\n",
    "\n",
    "train_metrics = torchmetrics.MetricTracker(metrics)\n",
    "val_metrics = torchmetrics.MetricTracker(metrics)\n",
    "test_metrics = torchmetrics.MetricTracker(metrics)\n",
    "\n",
    "\n",
    "seg_model = SegModel(\n",
    "    model,\n",
    "    lr=1e-3,\n",
    "    optimizer_type=\"adamw\",\n",
    "    train_metrics=train_metrics,\n",
    "    val_metrics=val_metrics,\n",
    "    test_metrics=test_metrics,\n",
    "    freeze_encoder=False,\n",
    ")\n",
    "data_module = SegDataModule(train_set, valid_set, test_set, batch_size=8)\n",
    "model_name = \"UNetPlusPlus_adamw_b8\"\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/satelite/\",\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"model-{}\".format(model_name),\n",
    ")\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=10, verbose=True, mode=\"min\"\n",
    ")\n",
    "\n",
    "tb_logger = TensorBoardLogger(\"lightning_logs/satelite/\", name=model_name)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=200,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    callbacks=[checkpoint_callback, early_stopping],\n",
    "    logger=tb_logger,\n",
    "    precision=16,  # Mixed precision training\n",
    ")\n",
    "\n",
    "trainer.fit(seg_model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   2048 B   |   3565 MiB |  22461 GiB |  22461 GiB |\\n|       from large pool |      0 B   |   3555 MiB |  22350 GiB |  22350 GiB |\\n|       from small pool |   2048 B   |     30 MiB |    110 GiB |    110 GiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   2048 B   |   3565 MiB |  22461 GiB |  22461 GiB |\\n|       from large pool |      0 B   |   3555 MiB |  22350 GiB |  22350 GiB |\\n|       from small pool |   2048 B   |     30 MiB |    110 GiB |    110 GiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |     16 B   |   3542 MiB |  22358 GiB |  22358 GiB |\\n|       from large pool |      0 B   |   3533 MiB |  22247 GiB |  22247 GiB |\\n|       from small pool |     16 B   |     29 MiB |    110 GiB |    110 GiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   6144 KiB |   3844 MiB |   5566 MiB |   5560 MiB |\\n|       from large pool |      0 KiB |   3812 MiB |   5528 MiB |   5528 MiB |\\n|       from small pool |   6144 KiB |     32 MiB |     38 MiB |     32 MiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |   6142 KiB | 411593 KiB |  10943 GiB |  10943 GiB |\\n|       from large pool |      0 KiB | 401408 KiB |  10831 GiB |  10831 GiB |\\n|       from small pool |   6142 KiB |  15836 KiB |    112 GiB |    112 GiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |       4    |    2450    |    2562 K  |    2562 K  |\\n|       from large pool |       0    |     177    |    1072 K  |    1072 K  |\\n|       from small pool |       4    |    2329    |    1489 K  |    1489 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |       4    |    2450    |    2562 K  |    2562 K  |\\n|       from large pool |       0    |     177    |    1072 K  |    1072 K  |\\n|       from small pool |       4    |    2329    |    1489 K  |    1489 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |       3    |      88    |     125    |     122    |\\n|       from large pool |       0    |      72    |     106    |     106    |\\n|       from small pool |       3    |      16    |      19    |      16    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       7    |     182    |    1001 K  |    1001 K  |\\n|       from large pool |       0    |      34    |     479 K  |     479 K  |\\n|       from small pool |       7    |     158    |     521 K  |     521 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
